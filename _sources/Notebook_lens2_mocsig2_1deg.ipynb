{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CESM2 - LARGE ENSEMBLE (LENS2)\n",
    "\n",
    "- The goal of this notebook is to calculate the MOC in density coordinates. We used https://github.com/sgyeager/POP_MOC as reference; thus, We thank Dr. Stephen Yeager. We also thank Michael Levy for the technical support. \n",
    "- P.S.: The Notebook is incomplete as we are adapting it to compute the MOC from all its components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr \n",
    "import numpy as np  \n",
    "import cftime\n",
    "import copy\n",
    "import scipy.stats\n",
    "from scipy import signal\n",
    "from functools import partial\n",
    "import glob\n",
    "import dask\n",
    "import cf_xarray\n",
    "import intake\n",
    "import pprint\n",
    "import intake_esm\n",
    "import matplotlib.pyplot as plt\n",
    "from xhistogram.xarray import histogram\n",
    "import pop_tools\n",
    "%matplotlib inline\n",
    "from MOCutils import popmoc\n",
    "from dask.distributed import Client\n",
    "from ncar_jobqueue import NCARCluster#,PBSCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the workflow using clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_per_worker = 100 # in GB more memory here maybe 100 GB\n",
    "num_workers = 45 # more workers maybe 45\n",
    "cluster = NCARCluster(cores=1, processes=1, memory=f'{mem_per_worker} GB',resource_spec=f'select=1:ncpus=1:mem={mem_per_worker}GB')\n",
    "cluster.scale(num_workers)\n",
    "client = Client(cluster)\n",
    "print(client)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in OGCM history file & MOC template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmoc = '/glade/u/home/yeager/analysis/python/POP_MOC/moc_template.nc'\n",
    "ds_moctemp = xr.open_dataset(fmoc) # MOC template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open original collection description file\n",
    "cat_url='/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'\n",
    "col = intake.open_esm_datastore(cat_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catolog\n",
    "print('Catalog file:', col.esmcol_data['catalog_file'])\n",
    "col.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_orig = col.unique(columns=['component', 'frequency', 'experiment', 'variable'])\n",
    "pprint.pprint(uniques_orig, compact=True, indent=1, width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables like temperature, salinity, are not available for annual frequency, so we chose the monthly frequency.\n",
    "col.search(component=\"ocn\", variable=[\"TEMP\",\"SALT\",\"UVEL\",\"VVEL\"], frequency=\"month_1\", experiment=\"historical\").df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_subset = col.search(component='ocn', # Ocean component\n",
    "                            variable=['TEMP','SALT','UVEL','VVEL','UISOP','USUBM','VISOP','VSUBM'], # Temperature, Salinity, Zonal Velocity, Meridional Velocity\n",
    "                            frequency='month_1', # Monthly\n",
    "                            experiment='historical') # 1850-2014\n",
    "#                            forcing_variant='smbb', # You can use smbb or cmip6\n",
    "#                       )\n",
    "dset_dict_raw = cat_subset.to_dataset_dict(zarr_kwargs={\"consolidated\": True}, storage_options={\"anon\": True})\n",
    "print(f\"\\nDataset dictionary keys:\\n {dset_dict_raw.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute sigma-2 field from LENS2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tslice = slice(\"1960-01-01\", \"2014-12-31\") # select the period you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_salt = dset_dict_raw['ocn.historical.pop.h.smbb.SALT'] # Salinity\n",
    "#ds_cmip6_salt = dset_dict_raw['ocn.historical.pop.h.cmip6.SALT'] # Salinity\n",
    "#ds_salt = xr.concat([ds_cmip6_salt,ds_smbb_salt], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f'Salinty before: {dask.utils.format_bytes(ds_smbb_salt.nbytes)}')\n",
    "ds_salt = ds_smbb_salt.sel(time=tslice)\n",
    "ds_salt = ds_salt.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "salt = ds_salt['SALT']\n",
    "salt = salt.mean(dim = [\"member_id\"]) # Average of all members\n",
    "print(f\"Salinty after: {dask.utils.format_bytes(salt.nbytes)}\")\n",
    "salt = salt.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_salt, ds_smbb_salt#, ds_cmip6_salt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_temp = dset_dict_raw['ocn.historical.pop.h.smbb.TEMP'] # Temperature\n",
    "#ds_cmip6_temp = dset_dict_raw['ocn.historical.pop.h.cmip6.TEMP'] # Temperature\n",
    "#ds_temp = xr.concat([ds_cmip6_temp,ds_smbb_temp], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f'Temperature before: {dask.utils.format_bytes(ds_smbb_temp.nbytes)}')\n",
    "ds_temp = ds_smbb_temp.sel(time=tslice)\n",
    "ds_temp = ds_temp.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "temp = ds_temp['TEMP']\n",
    "temp = temp.mean(dim = ['member_id']) # Average of all members\n",
    "print(f'Temperature after: {dask.utils.format_bytes(temp.nbytes)}')\n",
    "temp = temp.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_temp#, ds_cmip6_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zonal velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_uvel = dset_dict_raw['ocn.historical.pop.h.smbb.UVEL'] #  Zonal velocity\n",
    "#ds_cmip6_uvel = dset_dict_raw['ocn.historical.pop.h.cmip6.UVEL'] #  Zonal velocity\n",
    "#ds_uvel = xr.concat([ds_cmip6_uvel,ds_smbb_uvel], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f'Zonal Velocity before: {dask.utils.format_bytes(ds_smbb_uvel.nbytes)}')\n",
    "ds_uvel = ds_smbb_uvel.sel(time=tslice)\n",
    "ds_uvel = ds_uvel.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "uvel = ds_uvel['UVEL']\n",
    "uvel = uvel.mean(dim = ['member_id']) # Average of all members\n",
    "print(f'Zonal Velocity before: {dask.utils.format_bytes(uvel.nbytes)}')\n",
    "uvel = uvel.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_uvel#, ds_cmip6_uvel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meridional Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_vvel = dset_dict_raw['ocn.historical.pop.h.smbb.VVEL'] # meridional velocity\n",
    "#ds_cmip6_vvel = dset_dict_raw['ocn.historical.pop.h.cmip6.VVEL'] # meridional velocity\n",
    "#ds_vvel = xr.concat([ds_cmip6_vvel,ds_smbb_vvel], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f\"Meridional Velocity before: {dask.utils.format_bytes(ds_smbb_vvel.nbytes)}\")\n",
    "ds_vvel = ds_smbb_vvel.sel(time=tslice)\n",
    "ds_vvel = ds_vvel.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "vvel = ds_vvel['VVEL']\n",
    "vvel = vvel.mean(dim = ['member_id']) # Average of all members\n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(vvel.nbytes)}\")\n",
    "vvel = vvel.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_vvel#, ds_cmip6_vvel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submeso velocity in grid-x direction (diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_usubm = dset_dict_raw['ocn.historical.pop.h.smbb.USUBM'] # meridional velocity\n",
    "#ds_cmip6_usubm = dset_dict_raw['ocn.historical.pop.h.cmip6.USUBM'] # meridional velocity\n",
    "#ds_usubm = xr.concat([ds_cmip6_usubm,ds_smbb_usubm], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f\"Zonal Submeso Velocity before: {dask.utils.format_bytes(ds_smbb_usubm.nbytes)}\")\n",
    "ds_usubm = ds_smbb_usubm.sel(time=tslice)\n",
    "ds_usubm = ds_usubm.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "usubm = ds_usubm['USUBM']\n",
    "usubm = usubm.mean(dim = ['member_id']) # Average of all members\n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(usubm.nbytes)}\")\n",
    "usubm = usubm.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_usubm#, ds_cmip6_usubm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submeso velocity in grid-y direction (diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "ds_smbb_vsubm = dset_dict_raw['ocn.historical.pop.h.smbb.VSUBM'] # meridional velocity\n",
    "#ds_cmip6_vsubm = dset_dict_raw['ocn.historical.pop.h.cmip6.VSUBM'] # meridional velocity\n",
    "#ds_vsubm = xr.concat([ds_cmip6_vsubm,ds_smbb_vsubm], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f\"Meridional Submeso Velocity before: {dask.utils.format_bytes(ds_smbb_vsubm.nbytes)}\")\n",
    "ds_vsubm = ds_smbb_vsubm.sel(time=tslice)\n",
    "ds_vsubm = ds_vsubm.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "vsubm = ds_vsubm['VSUBM']\n",
    "vsubm = vsubm.mean(dim = ['member_id']) # Average of all members\n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(vsubm.nbytes)}\")\n",
    "vsubm = vsubm.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_vsubm#, ds_cmip6_vsubm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolus Velocity in grid-x direction (diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_uisop = dset_dict_raw['ocn.historical.pop.h.smbb.UISOP'] # meridional velocity\n",
    "#ds_cmip6_uisop = dset_dict_raw['ocn.historical.pop.h.cmip6.UISOP'] # meridional velocity\n",
    "#ds_uisop = xr.concat([ds_cmip6_uisop,ds_smbb_uisop], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f\"Meridional Submeso Velocity before: {dask.utils.format_bytes(ds_smbb_uisop.nbytes)}\")\n",
    "ds_uisop = ds_smbb_uisop.sel(time=tslice)\n",
    "ds_uisop = ds_uisop.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "uisop = ds_uisop['UISOP']\n",
    "uisop = uisop.mean(dim = ['member_id']) # Average of all members\n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(uisop.nbytes)}\")\n",
    "uisop = uisop.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_uisop#, ds_cmip6_uisop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bolus Velocity in grid-y direction (diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_visop = dset_dict_raw['ocn.historical.pop.h.smbb.VISOP'] # meridional velocity\n",
    "#ds_cmip6_visop = dset_dict_raw['ocn.historical.pop.h.cmip6.VISOP'] # meridional velocity\n",
    "#ds_visop = xr.concat([ds_cmip6_visop,ds_smbb_visop], dim='member_id',data_vars='minimal',coords='minimal',compat='override')\n",
    "print(f\"Meridional Submeso Velocity before: {dask.utils.format_bytes(ds_smbb_visop.nbytes)}\")\n",
    "ds_visop = ds_smbb_visop.sel(time=tslice)\n",
    "ds_visop = ds_visop.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "visop = ds_visop['VISOP']\n",
    "visop = visop.mean(dim = ['member_id']) # Average of all members\n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(visop.nbytes)}\")\n",
    "visop = visop.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_visop#, ds_cmip6_visop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute sigma-2 field from POP model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "refz = 2000\n",
    "refdep = xr.full_like(salt,refz).rename('REFDEP')\n",
    "\n",
    "# Sigma2 on model TLAT, TLONG\n",
    "sigma2_T = pop_tools.eos(salt=salt,temp=temp,depth=refdep) - 1000\n",
    "sigma2_T = sigma2_T.assign_attrs({'long_name':'Sigma referenced to {}m'.format(refz),'units':'kg/m^3'})\n",
    "\n",
    "## Following may be needed for some CESM2 LENS output (simulations run in Korea):\n",
    "#dims = np.shape(temp)\n",
    "#nt = dims[0]\n",
    "#nz = dims[1]\n",
    "#ny = dims[2]\n",
    "#nx = dims[3]\n",
    "#kji = np.indices((nz,ny,nx))\n",
    "#kindices = kji[0,:,:,:] + 1\n",
    "# apply T-grid mask\n",
    "#mask=kindices<=ds['KMT'].values[None,:,:]\n",
    "#sigma2_T = sigma2_T.where(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define target sigma-2 vertical grid\n",
    "#### * Use a predefined target grid, or create your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use predefined 86-layer sigma2 grid:\n",
    "sigma_mid,sigma_edge = popmoc.sigma2_grid_86L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute Isopycnal Layer Thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, test histogram by counting cells in each density bin. Vertical sum should be same as KMT.\n",
    "iso_count = histogram(sigma2_T, bins=[sigma_edge.values],dim=['z_t'],density=False)\n",
    "iso_count = iso_count.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "\n",
    "kmtdiff = iso_count.sum('sigma') - ds_temp['KMT']\n",
    "print(\"Max difference from true KMT = {}\".format(abs(kmtdiff).max().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use histogram to compute layer thickness. Vertical sum should be same as HT.\n",
    "dzwgts = (ds_temp['dz']/100.).assign_attrs({'units':'m'})\n",
    "iso_thick = histogram(sigma2_T, bins=[sigma_edge.values], weights=dzwgts,dim=['z_t'],density=False)\n",
    "iso_thick = iso_thick.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "iso_thick = iso_thick.rename('iso_thick').assign_attrs({'units':'m','long_name':'Isopycnal Layer Thickness'}).rename({'sigma':'sigma_mid'})\n",
    "iso_thick = iso_thick.transpose('time','sigma_mid','nlat','nlon')\n",
    "\n",
    "htdiff = iso_thick.sum('sigma_mid') - (ds_temp['HT']/100.).assign_attrs({'units':'m'})\n",
    "print(\"Max difference from true HT = {}m\".format(abs(htdiff).max().values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compute Isopycnal Layer Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum of layer thickness yields depth of layer edges:\n",
    "iso_depth = iso_thick.cumsum('sigma_mid').rename('iso_depth').rename({'sigma_mid':'sigma_bot'}).assign_attrs({'units':'m','long_name':'Isopycnal Layer Depth'})\n",
    "sigma_bot = sigma_edge.isel(sigma=slice(1,None)).rename({'sigma':'sigma_bot'}).assign_attrs({'long_name':'Sigma2 at bottom of layer'})\n",
    "iso_depth['sigma_bot'] = sigma_bot\n",
    "iso_depth = iso_depth.transpose('time','sigma_bot','nlat','nlon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_depth.isel(time=0,sigma_bot=84).plot(size=6,vmax=5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isopycnal depth of bottom-most layer should be same as HT.\n",
    "htdiff =  iso_depth.isel(sigma_bot=-1) - (ds_temp['HT']/100.).assign_attrs({'units':'m'})\n",
    "print(\"Max difference from true HT = {}m\".format(abs(htdiff).max().values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compute Isopycnal Layer Horizontal Volume Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid Metrics\n",
    "dxu = ds_uvel['DXU']\n",
    "dyu = ds_uvel['DYU']\n",
    "dxt = ds_temp['DXT']\n",
    "dyt = ds_temp['DYT']\n",
    "dz = ds_temp['dz']\n",
    "tarea = ds_temp['TAREA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_e = ds_uvel['UVEL']\n",
    "u_e = u_e.where(u_e<1.e30,0)\n",
    "u_i = ds_uisop['UISOP'].drop(['TLONG','ULAT'])\n",
    "u_i = u_i.where(u_i<1.e30,0)\n",
    "u_s = ds_usubm['USUBM'].drop(['TLONG','ULAT'])\n",
    "u_s = u_s.where(u_s<1.e30,0)\n",
    "v_e = ds_vvel['VVEL']\n",
    "v_e = v_e.where(v_e<1.e30,0)\n",
    "v_i = ds_visop['VISOP'].drop(['ULONG','TLAT'])\n",
    "v_i = v_i.where(v_i<1.e30,0)\n",
    "v_s = ds_vsubm['VSUBM'].drop(['ULONG','TLAT'])\n",
    "v_s = v_s.where(v_s<1.e30,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid-oriented Volume FLuxes:\n",
    "u_e = (u_e*dyu*dz/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "v_e = (v_e*dxu*dz/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "u_i = (u_i*dyt*dz/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "v_i = (v_i*dxt*dz/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "u_s = (u_s*dyt*dz/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "v_s = (v_s*dxt*dz/1.e6).assign_attrs({'units':'m^3/s'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert u_e,v_e to C-grid fluxes\n",
    "u_e = 0.5*(u_e+u_e.shift(nlat=1))\n",
    "v_e = 0.5*(v_e+v_e.roll(nlon=1,roll_coords=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine velocity components \n",
    "u = xr.concat([u_e,u_i,u_s],dim=ds_moctemp.moc_components)\n",
    "v = xr.concat([v_e,v_i,v_s],dim=ds_moctemp.moc_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Volume fluxes in density-space. \n",
    "iso_uflux = histogram(sigma2_T, bins=[sigma_edge.values],weights=u,dim=['z_t'],density=False)\n",
    "iso_uflux = iso_uflux.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "\n",
    "iso_vflux = histogram(sigma2_T, bins=[sigma_edge.values],weights=v,dim=['z_t'],density=False)\n",
    "iso_vflux = iso_vflux.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "\n",
    "# Look for fix to histogram keep_coords=True to avoid this step in future:\n",
    "iso_uflux = iso_uflux.assign_coords({'moc_components':ds_moctemp.moc_components})\n",
    "iso_vflux = iso_vflux.assign_coords({'moc_components':ds_moctemp.moc_components})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical sum in density-space should reproduce vertical sum in depth-space\n",
    "ufluxdiff = iso_uflux.sum('sigma') - u.sum('z_t')\n",
    "print(\"Max difference from true Uflux = {}\".format(abs(ufluxdiff).max().values))\n",
    "vfluxdiff = iso_vflux.sum('sigma') - v.sum('z_t')\n",
    "print(\"Max difference from true Vflux = {}\".format(abs(vfluxdiff).max().values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above large differences appear to be associated with the Nordic Sea overflow parameterization. I'm not sure how to handle overflow velocities in the MOC computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufluxdiff.isel(moc_comp=0).plot(size=7,vmin=-1.e5,vmax=1.e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Compute Vertical Volume Flux from horizontal flux convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wflux = popmoc.wflux(iso_uflux,iso_vflux,'sigma',sigma_edge,grid='C')\n",
    "wflux = wflux.assign_coords({'TLAT':ds['TLAT'],'TLONG':ds['TLONG']}).drop(['ULAT','ULONG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Define MOC region masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the MOC region mask:\n",
    "rmask = ds.REGION_MASK.drop(['ULONG','ULAT'])\n",
    "rmaskglob = xr.where((rmask>0),1,0)\n",
    "rmaskatl = xr.where((rmask>=6) & (rmask<=11),1,0)\n",
    "rmaskmoc = xr.concat([rmaskglob,rmaskatl],dim=ds_moctemp.transport_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmaskmoc.plot(levels=[0,1,2,3],col='transport_reg',size=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Compute MOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MOC = popmoc.compute_MOC(wflux,rmaskmoc,ds_moctemp.lat_aux_grid)\n",
    "MOC = MOC.transpose('time','transport_reg','moc_comp','sigma','lat_aux_grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Add Southern Boundary Fluxes for Atlantic Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine j=index of Atlantic region southern boundary\n",
    "tmp = rmaskmoc.isel(transport_reg=1).sum('nlon')\n",
    "atl_j = 0\n",
    "j = 0\n",
    "while (atl_j==0):\n",
    "    if (tmp.isel(nlat=j).data>0):\n",
    "        atl_j = j\n",
    "    j += 1\n",
    "atl_j = atl_j - 1\n",
    "atl_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmaskmoc.coords['TLAT'][84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add vflux at southern boundary of Atlantic domain\n",
    "tmp = iso_vflux*(rmaskmoc.shift(nlat=-1))\n",
    "tmp = tmp.isel(nlat=atl_j,transport_reg=1).sum('nlon')\n",
    "moc_s = -tmp.sortby('sigma',ascending=False).cumsum('sigma').sortby('sigma',ascending=True)/1.e6\n",
    "moc_s['sigma'] = sigma_edge.isel(sigma=slice(0,-1))\n",
    "MOC[{'transport_reg':1}] = MOC[{'transport_reg':1}] + moc_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOC.isel(time=0).isel(transport_reg=0,moc_comp=0).plot(ylim=[40,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOC.isel(time=0).isel(transport_reg=1,moc_comp=0).plot(ylim=[40,28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Save to netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsout = MOC.to_dataset()\n",
    "dsout['iso_thick'] = iso_thick\n",
    "dsout['iso_depth'] = iso_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out_MOC = xr.merge([MOC.rename('MOC')])\n",
    "ds_out_MOC.attrs['description'] = 'Meridional overturning circulation (MOC)'\n",
    "ds_out_MOC.attrs['units'] = 'Sv'\n",
    "ds_out_MOC.attrs['author'] = 'Mauricio Rocha'\n",
    "ds_out_MOC.attrs['email'] = 'mauricio.rocha@usp.br'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define k-index array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.shape(temp)\n",
    "#ne = dims[0] # ensember member\n",
    "nt = dims[0]  # time\n",
    "nz = dims[1]  # depth\n",
    "ny = dims[2]  # latitude\n",
    "nx = dims[3]  # longitude\n",
    "kji = np.indices((nz,ny,nx))\n",
    "kindices = kji[0,:,:,:] + 1 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cluster.scale(20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "ds_smbb_temp = xr.open_mfdataset(\"/glade/campaign/cgd/cesm/CESM2-LE/timeseries/ocn/proc/tseries/month_1/TEMP/b.e21.BHISTcmip6.f09_g17.LE2-1281.*.pop.h.TEMP.196001-196912.nc\",\n",
    "                                 combine=\"nested\",\n",
    "                                 concat_dim=\"member_id\",\n",
    "                                ).mean('member_id')\n",
    "#ds_smbb_temp = ds_smbb_temp.sel(time=slice(\"1960\", \"1961\"))\n",
    "ds_smbb_temp = ds_smbb_temp.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "#temp = ds_smbb_temp['TEMP'].isel(time=slice(0,1)).load()\n",
    "temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temp = temp.load()\n",
    "temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Salinity\n",
    "ds_smbb_salt = xr.open_mfdataset(\"/glade/campaign/cgd/cesm/CESM2-LE/timeseries/ocn/proc/tseries/month_1/SALT/b.e21.BHISTcmip6.f09_g17.LE2*.pop.h.SALT.196001-196912.nc\",\n",
    "                                 combine=\"nested\",\n",
    "                                 concat_dim=\"member_id\",\n",
    "                                ).mean('member_id')\n",
    "#ds_smbb_salt = ds_smbb_salt.sel(time=slice(\"1960\", \"1961\"))\n",
    "ds_smbb_salt = ds_smbb_salt.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "salt = ds_smbb_salt['SALT'].isel(time=slice(0,10)).compute()\n",
    "salt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define sigma2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refz = 2000 # reference depth\n",
    "refdep = xr.full_like(salt,refz).rename('REFDEP')\n",
    "# Sigma2 on model TLAT, TLONG\n",
    "sigma2_T = pop_tools.eos(salt=salt,temp=temp,depth=refdep) - 1000\n",
    "sigma2_T = sigma2_T.assign_attrs({'long_name':'Sigma referenced to {}m'.format(refz),'units':'kg/m^3'})\n",
    "sigma2_T = sigma2_T.mean(dim=[\"time\"]) # Average over time\n",
    "# apply T-grid mask\n",
    "#mask=kindices<=ds['KMT'].values[None,:,:]\n",
    "#sigma2_T = sigma2_T.where(mask)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pop_tools.eos(salt=salt,temp=temp,depth=refdep) - 1000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "salt.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target sigma-2 vertical grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use predefined 86-layer sigma2 grid:\n",
    "sigma_mid,sigma_edge = popmoc.sigma2_grid_86L()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sigma_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute MOC(Sigma2) using xhistogram "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fpop = '/glade/scratch/yeager/POP_MOC/g210.GIAF_JRA.v14.gx1v7.02.pop.h.0157-01.nc'\n",
    "ds = xr.open_dataset(fpop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute Isopycnal Layer Thickness"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(dask.distributed.__version__)\n",
    "print(pop_tools.__version__)\n",
    "print(xr.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sigma2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here, test histogram by counting cells in each density bin. Vertical sum should be same as KMT.\n",
    "iso_count = histogram(sigma2_T, bins=[sigma_edge.values],dim=['z_t'],density=False)\n",
    "iso_count = iso_count.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "kmtdiff = (iso_count.sum('sigma') - ds_smbb_temp['KMT'].mean(dim=[\"time\"]))\n",
    "print(\"Max difference from true KMT = {}\".format(abs(kmtdiff).max().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use histogram to compute layer thickness. Vertical sum should be same as HT.\n",
    "dzwgts = (ds_smbb_temp['dz']/100.).assign_attrs({'units':'m'})\n",
    "dzwgts = dzwgts.mean(dim=[\"time\"]) # Average over time\n",
    "iso_thick = histogram(sigma2_T, bins=[sigma_edge.values], weights=dzwgts,dim=['z_t'],density=False)\n",
    "iso_thick = iso_thick.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "iso_thick = iso_thick.rename('Isopycnal Layer Thickness').assign_attrs({'units':'m'})\n",
    "htdiff = iso_thick.sum('sigma') - (ds_smbb_temp['HT']/100.).assign_attrs({'units':'m'})\n",
    "htdiff = htdiff.mean(dim=[\"time\"]) # Average over time\n",
    "print(\"Max difference from true HT = {}m\".format(abs(htdiff).max().values))\n",
    "#In the original Notebook, the maximum difference is: HT = 1.2270752449694555e-05m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute Isopycnal Layer Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum of layer thickness yields depth of layer edges:\n",
    "iso_depth = iso_thick.cumsum('sigma').rename('Isopycnal Layer Depth')\n",
    "iso_depth['sigma'] = sigma_edge.isel(sigma=slice(1,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_depth.isel(sigma=84).plot(size=6,vmax=5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isopycnal depth of bottom edge should be same as HT.\n",
    "htdiff =  iso_depth.isel(sigma=-1) - (ds_smbb_temp['HT']/100.).assign_attrs({'units':'m'})\n",
    "htdiff = htdiff.mean(dim=[\"time\"]) # Average over time\n",
    "print(\"Max difference from true HT = {}m\".format(abs(htdiff).max().values))\n",
    "#Max difference from true HT = 1.2270752449694555e-05m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute Isopycnal Layer Horizontal Volume Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid-oriented Volume FLuxes:\n",
    "uvel = uvel.where(uvel<1.e30).fillna(0.)\n",
    "vvel = vvel.where(vvel<1.e30).fillna(0.)\n",
    "uvel = (uvel*ds_smbb_uvel['DYU']*ds_smbb_uvel['dz']/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "vvel = (vvel*ds_smbb_vvel['DXU']*ds_smbb_vvel['dz']/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "uvel = uvel.mean(dim=[\"time\"]) # Average over time\n",
    "vvel = vvel.mean(dim=[\"time\"]) # Average over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume fluxes in density-space. Vertical sum is density-space should reproduce vertical sum in depth-space.\n",
    "iso_uflux = histogram(sigma2_T, bins=[sigma_edge.values],weights=uvel,dim=['z_t'],density=False) # The 'numpy.histogram_bin_edges' function is not implemented by Dask array.\n",
    "iso_uflux = iso_uflux.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "iso_vflux = histogram(sigma2_T, bins=[sigma_edge.values],weights=vvel,dim=['z_t'],density=False)\n",
    "iso_vflux = iso_vflux.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "\n",
    "ufluxdiff = iso_uflux.sum('sigma') - uvel.sum('z_t')\n",
    "vfluxdiff = iso_vflux.sum('sigma') - vvel.sum('z_t')\n",
    "print(\"Max difference from true Uflux = {}\".format(abs(ufluxdiff).max().values))\n",
    "print(\"Max difference from true Vflux = {}\".format(abs(vfluxdiff).max().values))\n",
    "#Max difference from true Uflux = 1367813.3765927013\n",
    "#Max difference from true Vflux = 456888.7641561439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to investigate these differences, which appear to be associated with overflows. The difference plot below shows zero almost everywhere except near Nordic Seas overflow points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufluxdiff.plot(size=7,vmin=-1.e5,vmax=1.e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compute Vertical Volume Flux using model divergence operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wflux = popmoc.pop_isowflux(iso_uflux,iso_vflux,'sigma',sigma_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Compute Zonal Sums of Vertical Volume Flux in latitude strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predefined 1-degree target latitude grid:\n",
    "lat_mid,lat_edge = popmoc.latitude_grid_1deg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MOC region mask with legend:\n",
    "rmask = ds_smbb_temp.REGION_MASK\n",
    "rmask=rmask.mean(dim=[\"time\"])\n",
    "rmaskmoc = rmask.where(rmask>0)\n",
    "rmaskmoc = xr.where((rmask>0),1,rmaskmoc)\n",
    "rmaskmoc = xr.where((rmask>=6) & (rmask<=11),2,rmaskmoc)\n",
    "rmaskmoc.plot(levels=[0,1,2,3]);\n",
    "rmaskmoc.attrs['legend'] = {0:\"Global\",1:\"IndoPac+SO\",2:\"Atlantic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea = ds_smbb_temp['TAREA']\n",
    "tarea=tarea.mean(dim=[\"time\"])\n",
    "tlat = ds_smbb_temp['TLAT']\n",
    "wflux_zonsum = popmoc.mesh_zonalavg(wflux,tarea,tlat,rmaskmoc,rmaskmoc.legend,lat_edge,sum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Compute cumulative meridional integral of zonally-summed wflux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A southward cumulative integral from 90N avoids issues associated with southern boundary of Atlantic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc = -wflux_zonsum.sel(lat=slice(None,None,-1)).cumsum('lat').sel(lat=slice(None,None,-1))\n",
    "moc = (moc/1.e6).assign_attrs({'units':'Sv'})   \n",
    "moc.name = 'MOC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=0).plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=1).plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=2).plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=[1,2]).sum('region').plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2022b",
   "language": "python",
   "name": "npl-2022b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
