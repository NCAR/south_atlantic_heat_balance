{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0029a096-b302-4db3-8354-0674e6a67332",
   "metadata": {},
   "source": [
    "## CESM2 - LARGE ENSEMBLE (LENS2)\n",
    "\n",
    "- The purpose of this notebook is to calculate the time series of the annual cycle and the anomaly of volume transport and heat content. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5205d6-0d21-42d9-8cae-989582973398",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb6356-08ac-4111-b8bf-58bdccfe4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules I am using in this example\n",
    "import xarray as xr\n",
    "import xgcm\n",
    "from xgcm import Grid\n",
    "import pop_tools\n",
    "from dask.distributed import Client, wait\n",
    "from ncar_jobqueue import NCARCluster\n",
    "import dask\n",
    "import intake\n",
    "import intake_esm\n",
    "import dask\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings, getpass, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75257b34-40de-4cf9-992c-8ca1e3bfc1f1",
   "metadata": {},
   "source": [
    "### Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574aa21b-3351-4c2f-833e-c32502fa7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_per_worker = 50 # memory per worker in GB \n",
    "num_workers = 40 # number of workers\n",
    "cluster = NCARCluster(cores=1, processes=1, memory=f'{mem_per_worker} GB',resource_spec=f'select=1:ncpus=1:mem={mem_per_worker}GB', walltime='1:00:00')\n",
    "cluster.scale(num_workers)\n",
    "client = Client(cluster)\n",
    "print(client)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1694a-0d53-43c8-916b-02eba35a7122",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f77c8c-e2cc-4891-a435-4ebc7a2e8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_esm_datastore(\n",
    "    '/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'\n",
    ")\n",
    "cat_subset = catalog.search(component='ocn',variable=['VVEL'],frequency='month_1')\n",
    "# Load catalog entries for subset into a dictionary of xarray datasets\n",
    "dset_dict_raw  = cat_subset.to_dataset_dict(zarr_kwargs={'consolidated': True},cdf_kwargs={'chunks': {'time': 12,'z_t': 1}}, storage_options={'anon': True})\n",
    "print(f'\\nDataset dictionary keys:\\n {dset_dict_raw.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9de98-74dd-4596-b07a-e74ed3cd0c43",
   "metadata": {},
   "source": [
    "### Concatenation of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93878b34-582d-4fb9-b1ba-2ce09bdd22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=('cmip6','smbb')               # Forcings\n",
    "fb=(['VVEL']) # Variable\n",
    "\n",
    "ds_dict = dict()\n",
    "for var in fb:\n",
    "    # 1- combine historical and ssp370 (concatenate in time)\n",
    "    ds_dict_tmp = dict()\n",
    "    for scenario in ff:\n",
    "        ds_dict_tmp[scenario] = xr.combine_nested([dset_dict_raw[f'ocn.historical.pop.h.{scenario}.{var}'], dset_dict_raw[f'ocn.ssp370.pop.h.{scenario}.{var}']],concat_dim=['time'])\n",
    "        \n",
    "        # 2- combine cmip6 and smbb (concatenate in member_id)\n",
    "    ds_dict[var] = xr.combine_nested([ds_dict_tmp['cmip6'], ds_dict_tmp['smbb']], concat_dim=['member_id'])\n",
    "    del ds_dict_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f8a24-2def-4725-ba5b-470d2a9e2c97",
   "metadata": {},
   "source": [
    "### Import POP grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33884e-1458-4337-8349-25a7ea915181",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_grid = pop_tools.get_grid('POP_gx1v7')\n",
    "ds_dict['TLONG'] = pop_grid.TLONG; ds_dict['TLAT'] = pop_grid.TLAT\n",
    "ds_dict['ULONG'] = pop_grid.ULONG; ds_dict['ULAT'] = pop_grid.ULAT\n",
    "del pop_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0841c5e-9269-44e6-b7b6-c51b561b9af2",
   "metadata": {},
   "source": [
    "### Cut and center the variable in the South Atlantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55e3db-9132-499b-914d-9c4c556ffe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cutting out and centering the variables in the South Atlantic\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": True})\n",
    "ilon1, flon1, ilon2, flon2 = 307, 320, 0, 54 # longitude (initial (i), final (f)) \n",
    "ilan = 0 # northernmost latitude\n",
    "ilas = -34 # southernmost latitude\n",
    "\n",
    "fb=(['VVEL'])\n",
    "\n",
    "for var in fb:\n",
    "    ds_dict[f'{var}']=xr.combine_nested([[\n",
    "        ds_dict[f'{var}'].where((ds_dict[f'{var}'].TLAT >= ilas) & (ds_dict[f'{var}'].TLAT <= ilan), drop=True).isel(\n",
    "            nlon = slice(ilon1,flon1)),\n",
    "        ds_dict[f'{var}'].where((ds_dict[f'{var}'].TLAT >= ilas) & (ds_dict[f'{var}'].TLAT <= ilan), drop=True).isel(\n",
    "            nlon = slice(ilon2,flon2))]],\n",
    "        concat_dim=['nlat','nlon'])   \n",
    "    ds_dict[f'{var}'].coords['nlon'] = (ds_dict[f'{var}'].coords['nlon'] + 180) % 360 - 180 \n",
    "    ds_dict[f'{var}'] = ds_dict[f'{var}'].sortby(ds_dict[f'{var}'].nlon)\n",
    "del ilan, ilas, ilon1, flon1, ilon2, flon2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab1be7f-eecf-42b4-bac3-fba6f6b4f9a4",
   "metadata": {},
   "source": [
    "### Mask the continent "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab2a127e-0631-49a9-9a94-ae58ec7f16e7",
   "metadata": {},
   "source": [
    "fb=(['TEMP'])\n",
    "for var in fb:\n",
    "    mask_array = dict()\n",
    "    mask_ocean = 2 * np.ones((len(ds_dict[f'{var}'][f'{var}'].coords['nlat']), # ocean\n",
    "                          len(ds_dict[f'{var}'][f'{var}'].coords['nlon']))\n",
    "                        ) * np.isfinite(ds_dict[f'{var}'][f'{var}'].isel(time=0))  \n",
    "    mask_land  = 1 * np.ones((len(ds_dict[f'{var}'][f'{var}'].coords['nlat']), # continent\n",
    "                          len(ds_dict[f'{var}'][f'{var}'].coords['nlon']))\n",
    "                        ) * np.isnan(ds_dict[f'{var}'][f'{var}'].isel(time=0))  \n",
    "    mask_array[f'{var}'] = mask_ocean + mask_land\n",
    "    ds_dict[f'{var}']['TAREA']=ds_dict[f'{var}']['TAREA'].where(mask_array[f'{var}'] != 1.).isel(time=0,member_id=0)*1e-4 # 1e-4 to convert cm2 into m2\n",
    "    del mask_array"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7096256f-b440-4bc6-9e32-1b1d3bf73de6",
   "metadata": {},
   "source": [
    "# Test\n",
    "ds_dict['TEMP']['TAREA'].isel(z_t=-10).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf192fb-cf06-4558-bf77-29f0d7d89600",
   "metadata": {},
   "source": [
    "#### Let's split heat transport into velocity $(\\rm{V})$ and temperature $(\\rm{T})$ components as follows:\n",
    "#### Equation (1): $$\\rm{VT} = (\\rm{\\bar{V}+V^{'})(\\bar{T}+T^{'})},$$\n",
    "#### Equation (2): $$\\rm{VT} = \\rm{\\bar{V}\\bar{T}+\\bar{V}T^{'}+V^{'}\\bar{T}+V^{'}T^{'}},$$\n",
    "##### where $(\\bar{})$ represents the climatology annual mean and $(^{'})$  represents the anomaly regarding the annual mean. However in place of temperature we will use the Heat Storage (HS) previously calculated (see Notebook_lens2_South_Atlantic_heat_balance.ipynb) and instead of velocity we will use the volume transport calculated as follows:\n",
    "\n",
    "#### Vertical Integration\n",
    "#### Equation (3): $$\\rm{VINT_Z = \\int_{z_2}^{z_1}VVEL~dz},$$\n",
    "##### where:\n",
    "##### * $\\rm{VVEL}$ ($\\rm{m~s^{-1}}$) is the meridional velocity,\n",
    "##### * $\\rm{VINT_Z}$ ($\\rm{m^{2}~s^{-1}}$) is the vertically integrated meridional velocity,\n",
    "##### * $\\rm{z_1}$ and $\\rm{z_2}$ are the depths limit on the integral. We consider the integral of the velocity from the surface to the bottom, and\n",
    "##### * $\\rm{dz}$ ($\\rm{m}$) is the spacing of each velocity cell. \n",
    "#### Zonal integration\n",
    "#### Equation (4): $$\\rm{VINT_{ZX} = \\int_{x_2}^{x_1}VINT_Z~DXT},$$\n",
    "##### where:\n",
    "##### * $\\rm{VINT_{ZX}}$ ($\\rm{m^{3}~s^{-1}}$) is the vertically integrated meridional velocity and integrated zonally, i.e., the volume transport,\n",
    "##### * $\\rm{x_1}$ and $\\rm{x_2}$ are the zonal limit on the integral. We consider the integral of the velocity from from the west side to the east side of the basin, and\n",
    "##### * $\\rm{DXT}$ ($\\rm{m}$) is the x-spacing centered at T points.\n",
    "#### Differentiation\n",
    "#### Equation (5): $$\\rm{Vol = VINT^{ilan}_{ZX}-VINT^{ilas}_{ZX}},$$\n",
    "##### where $\\rm{Vol}$ ($\\rm{m^{3}~s^{-1}}$) is the difference in volume transport ($\\rm{VINT_{ZX}}$) between the northernmost latitude ($\\rm{ilan}$) and the southernmost latitude ($\\rm{ilas}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86654aa2-4b81-41ea-8f12-72a1bed8dd3c",
   "metadata": {},
   "source": [
    "#### Volume Transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14540a2-ef46-43e3-adb9-31ea4c48bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx=ds_dict['VVEL']['DXT'].isel(time=0,member_id=0)*0.01 # (0.01 to convert cm into m)\n",
    "dz=ds_dict['VVEL']['dz'].isel(member_id=0,time=0,nlon=0,nlat=0)*0.01 # (0.01 to convert cm into m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48edaddd-dcd3-497f-9835-1fa84bcc1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "warnings.simplefilter(\"ignore\")\n",
    "Vol_array = list() # Build a list\n",
    "# Volume Transport\n",
    "for member_id in range(len(ds_dict['VVEL']['VVEL'].coords['member_id'])-99):  \n",
    "    VINTZ=(ds_dict['VVEL']['VVEL'].isel(member_id=member_id)*dz).sum(dim=['z_t']) # m2/s (0.01 to convert cm into m)\n",
    "    VINTZX=(VINTZ*dx).sum(dim=['nlon']) # m3/s \n",
    "    Vol=(VINTZX.isel(nlat=-1)-VINTZX.isel(nlat=0)).compute() # m3/s\n",
    "    del VINTZX, VINTZ\n",
    "    Vol_array.append(Vol) \n",
    "    print(f'Done with member: {member_id}')\n",
    "Vol_array_merged = xr.concat(Vol_array, dim='member_id', compat='override', join='override', coords='minimal') # concat the members      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26b802-ae68-4386-8143-162f6efb05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out_var = xr.merge([Vol_array_merged.rename('Vol')]) # Volume Transport\n",
    "ds_out_var.attrs['description'] = 'Volume transport in the South Atlantic'\n",
    "ds_out_var.attrs['units'] = 'm3/s'\n",
    "ds_out_var.attrs['author'] = 'Mauricio Rocha'\n",
    "ds_out_var.attrs['email'] = 'mauricio.rocha@usp.br'\n",
    "# create a directory on scratch to save the output\n",
    "path = '/glade/scratch/mauricio/Data/LENS2/HEAT_BALANCE/'.format(getpass.getuser())\n",
    "os.system('mkdir -p '+path)\n",
    "ds_out_var.to_netcdf(path+'volume_transport.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82172e-ae9d-4405-8177-0ea8b3a51ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "climatology_vol=xr.DataArray(np.tile(ds_out_var.Vol.groupby('time.month').mean('time').values,(1,251)), \n",
    "                         coords=ds_out_var.Vol.coords, \n",
    "                         dims=ds_out_var.Vol.dims, \n",
    "                         attrs=ds_out_var.Vol.attrs)\n",
    "anomalies_vol= ds_out_var.Vol.groupby('time.month') - ds_out_var.Vol.groupby('time.month').mean('time')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4f72d0a-9a10-4bea-8d1d-2a6c8897e36d",
   "metadata": {},
   "source": [
    "# Test\n",
    "Vol_array_merged.resample(time='1Y',closed='left').mean('time').sel(time=slice('1960-01-01','2100-12-31')).plot.line(x='time',color='blue',alpha=0.1,label=None)\n",
    "Vol_array_merged.resample(time='1Y',closed='left').mean('time').sel(time=slice('1960-01-01','2100-12-31')).mean(dim=['member_id']).plot(linewidth=2,color='blue')\n",
    "plt.legend('',frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5037102-6875-4cb1-81c2-26ac53ccafa2",
   "metadata": {},
   "source": [
    "### 2- Compute the Heat Content\n",
    "#### Spacial integration\n",
    "#### Equation (4): $$\\rm{TINT = \\int_{z_2}^{z_1}\\int_{y_2}^{y_1}\\int_{x_2}^{x_1}TEMP_{(z)}~dxdydz},$$\n",
    "##### where:\n",
    "##### * $\\rm{TEMP}$ ($\\rm{^{o}C}$) is the temperature, and \n",
    "##### * $\\rm{TINT}$ ($\\rm{^{o}C~m^{3}}$) is the integrated temperature in the three spatial dimensions (x, y, and z).\n",
    "#### Density and Specific Heat\n",
    "#### Equation (5): $$\\rm{OHC = TINT*\\uprho_\\uptheta*C_p},$$\n",
    "##### where:\n",
    "##### * $\\rm{OHC}$ ($\\rm{J}$) is the Heat Content,\n",
    "##### * $\\uprho_\\uptheta$ ($\\rm{kg~m^{-3}}$) is the density of sea water, and\n",
    "##### * $\\rm{C_p}$ ($\\rm{J~^{o}C^{-1}~kg^{-1}}$) is the specific heat of sea water."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9ac4b11-839f-4d7a-98eb-15cf0d54f51f",
   "metadata": {},
   "source": [
    "%%time\n",
    "OHC_array = list() # Build a list\n",
    "for member_id in range(len(ds_dict['TEMP']['TEMP'].coords['member_id'])-99): \n",
    "    TINT=(ds_dict['TEMP']['TEMP'].isel(member_id=member_id)*ds_dict['TEMP']['TAREA']*dz).sum(\n",
    "        dim=['nlat','nlon','z_t']) # oC.m3 (0.01 to convert cm into m)\n",
    "    OHC=(TINT*1026*3996).load()\n",
    "    OHC_array.append(OHC) \n",
    "    print(f'Done with member: {member_id}')\n",
    "OHC_array_merged = xr.concat(OHC_array, dim='member_id', compat='override', join='override', coords='minimal') # concat the members   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3635499-a041-4385-8a5c-98a53bdbb26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/glade/scratch/mauricio/Data/LENS2/HEAT_BALANCE/heat_balance_components.nc')\n",
    "ds=((ds/1026)/3996)*1e+15\n",
    "climatology_HS=xr.DataArray(np.tile(ds.HS_TEND_TEMP.groupby('time.month').mean('time').values,(1,251)), \n",
    "                         coords=ds.HS_TEND_TEMP.coords, \n",
    "                         dims=ds.HS_TEND_TEMP.dims, \n",
    "                         attrs=ds.HS_TEND_TEMP.attrs)\n",
    "anomalies_HS= ds.HS_TEND_TEMP.groupby('time.month') - ds.HS_TEND_TEMP.groupby('time.month').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e66156-3079-4ef5-bb0f-06a5ebdaac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "(climatology_HS.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)*climatology_vol.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)).plot.line(x='time',color='blue',label=r'$\\rm{\\bar{V}\\bar{T}}$')\n",
    "\n",
    "\n",
    "(climatology_HS.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)*anomalies_vol.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)).plot.line(x='time',color='red',label=r'$\\rm{\\bar{T}V{^\\prime}}$')\n",
    "\n",
    "\n",
    "(anomalies_HS.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)*climatology_vol.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)).plot.line(x='time',color='green',label=r'$\\rm{\\bar{V}T{^\\prime}}$')\n",
    "\n",
    "\n",
    "(anomalies_HS.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)*anomalies_vol.resample(time='1Y',closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).isel(\n",
    "    member_id=0)).plot.line(x='time',color='black',label=r'$\\rm{V{^\\prime}T{^\\prime}}$')\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.7)\n",
    "plt.legend()\n",
    "plt.title(None)\n",
    "plt.ylabel(r'$\\rm{{^{o}C}}m^{6}s^{-2}$')\n",
    "plt.xlabel('Time [Years]')\n",
    "plt.savefig('heat_transport_decomposition.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e315f-b169-4164-954d-2d81cf37f8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2022b",
   "language": "python",
   "name": "npl-2022b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
