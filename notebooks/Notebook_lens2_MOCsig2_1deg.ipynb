{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CESM2 - LARGE ENSEMBLE (LENS2)\n",
    "\n",
    "#### by Mauricio Rocha and Dr. Gustavo Marques\n",
    "\n",
    "- The goal of this notebook is to calculate the MOC in density coordinates. We used https://github.com/sgyeager/POP_MOC as reference; thus, We thank Dr. Stephen Yeager. We also thank Michael Levy for the technical support. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr \n",
    "import numpy as np  \n",
    "import cftime\n",
    "import copy\n",
    "import scipy.stats\n",
    "from scipy import signal\n",
    "from functools import partial\n",
    "import glob\n",
    "import dask\n",
    "import cf_xarray\n",
    "import intake\n",
    "import pprint\n",
    "import intake_esm\n",
    "import matplotlib.pyplot as plt\n",
    "from xhistogram.xarray import histogram\n",
    "import pop_tools\n",
    "%matplotlib inline\n",
    "from MOCutils import popmoc\n",
    "from dask.distributed import Client\n",
    "from ncar_jobqueue import NCARCluster#,PBSCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the workflow using clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_per_worker = 90 # in GB more memory here maybe 100 GB\n",
    "num_workers = 45 # more workers maybe 45\n",
    "cluster = NCARCluster(cores=1, processes=1, memory=f'{mem_per_worker} GB',resource_spec=f'select=1:ncpus=1:mem={mem_per_worker}GB')\n",
    "cluster.scale(num_workers)\n",
    "client = Client(cluster)\n",
    "print(client)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in OGCM history file & MOC template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmoc = '/glade/u/home/yeager/analysis/python/POP_MOC/moc_template.nc'\n",
    "ds_moctemp = xr.open_dataset(fmoc) # MOC template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open original collection description file\n",
    "cat_url='/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'\n",
    "col = intake.open_esm_datastore(cat_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catolog\n",
    "print(\"Catalog file:\", col.esmcol_data[\"catalog_file\"])\n",
    "col.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques_orig = col.unique(columns=[\"component\", \"frequency\", \"experiment\", \"variable\"])\n",
    "pprint.pprint(uniques_orig, compact=True, indent=1, width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables like temperature, salinity, are not available for annual frequency, so we chose the monthly frequency.\n",
    "col.search(component=\"ocn\", variable=[\"TEMP\",\"SALT\",\"UVEL\",\"VVEL\"], frequency=\"month_1\", experiment=\"historical\").df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_subset = col.search(component='ocn', # ocean component\n",
    "                            variable=['TEMP','SALT','UVEL','VVEL'], # temperature, salinity, zonal velocity, meridional velocity\n",
    "                            frequency='month_1', # monthly\n",
    "                            experiment='historical', # 1850-2014\n",
    "                            forcing_variant='smbb', # you can use smbb or cmip6\n",
    "                       )\n",
    "dset_dict_raw = cat_subset.to_dataset_dict(zarr_kwargs={\"consolidated\": True}, storage_options={\"anon\": True})\n",
    "print(f\"\\nDataset dictionary keys:\\n {dset_dict_raw.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute sigma-2 field from LENS2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tslice = slice(\"1960-01-01\", \"2014-12-31\") # select the period you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_salt = dset_dict_raw['ocn.historical.pop.h.smbb.SALT'] # Salinity\n",
    "print(f\"Salinty before: {dask.utils.format_bytes(ds_smbb_salt.nbytes)}\")\n",
    "ds_smbb_salt = ds_smbb_salt.sel(time=tslice)\n",
    "ds_smbb_salt = ds_smbb_salt.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "salt = ds_smbb_salt['SALT']\n",
    "salt = salt.mean(dim = [\"member_id\"]) # Average of all members\n",
    "print(f\"Salinty after: {dask.utils.format_bytes(salt.nbytes)}\")\n",
    "salt = salt.load() # Necessary because pop-tools.eos() doesn't play nicely with dask\n",
    "del ds_smbb_salt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_temp = dset_dict_raw['ocn.historical.pop.h.smbb.TEMP'] # Temperature\n",
    "print(f\"Temperature before: {dask.utils.format_bytes(ds_smbb_temp.nbytes)}\")\n",
    "ds_smbb_temp = ds_smbb_temp.sel(time=tslice)\n",
    "ds_smbb_temp = ds_smbb_temp.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "temp = ds_smbb_temp['TEMP']\n",
    "temp = temp.mean(dim = [\"member_id\"]) # Average of all members\n",
    "print(f\"Temperature after: {dask.utils.format_bytes(temp.nbytes)}\")\n",
    "temp = temp.load() # Necessary because pop-tools.eos() doesn't play nicely with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zonal velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_smbb_uvel = dset_dict_raw['ocn.historical.pop.h.smbb.UVEL'] #  Zonal velocity \n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(ds_smbb_uvel.nbytes)}\")\n",
    "ds_smbb_uvel = ds_smbb_uvel.sel(time=tslice)\n",
    "ds_smbb_uvel = ds_smbb_uvel.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "uvel = ds_smbb_uvel['UVEL']\n",
    "uvel = uvel.mean(dim = [\"member_id\"]) # Average of all members\n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(uvel.nbytes)}\")\n",
    "uvel = uvel.load() # Necessary because pop-tools.eos() doesn't play nicely with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meridional Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Meridional velocity \n",
    "ds_smbb_vvel = dset_dict_raw['ocn.historical.pop.h.smbb.VVEL'] #  meridional velocity \n",
    "print(f\"Meridional Velocity before: {dask.utils.format_bytes(ds_smbb_vvel.nbytes)}\")\n",
    "ds_smbb_vvel = ds_smbb_vvel.sel(time=tslice)\n",
    "ds_smbb_vvel = ds_smbb_vvel.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "vvel = ds_smbb_vvel['VVEL']\n",
    "vvel = vvel.mean(dim = [\"member_id\"]) # Average of all members\n",
    "print(f\"Zonal Velocity before: {dask.utils.format_bytes(vvel.nbytes)}\")\n",
    "vvel = vvel.load() # Necessary because pop-tools.eos() doesn't play nicely with dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define k-index array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.shape(temp)\n",
    "#ne = dims[0] # ensember member\n",
    "nt = dims[0]  # time \n",
    "nz = dims[1]  # depth\n",
    "ny = dims[2]  # latitude\n",
    "nx = dims[3]  # longitude\n",
    "kji = np.indices((nz,ny,nx))\n",
    "kindices = kji[0,:,:,:] + 1 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cluster.scale(20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "ds_smbb_temp = xr.open_mfdataset(\"/glade/campaign/cgd/cesm/CESM2-LE/timeseries/ocn/proc/tseries/month_1/TEMP/b.e21.BHISTcmip6.f09_g17.LE2-1281.*.pop.h.TEMP.196001-196912.nc\",\n",
    "                                 combine=\"nested\",\n",
    "                                 concat_dim=\"member_id\",\n",
    "                                ).mean('member_id')\n",
    "#ds_smbb_temp = ds_smbb_temp.sel(time=slice(\"1960\", \"1961\"))\n",
    "ds_smbb_temp = ds_smbb_temp.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "#temp = ds_smbb_temp['TEMP'].isel(time=slice(0,1)).load()\n",
    "temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temp = temp.load()\n",
    "temp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Salinity\n",
    "ds_smbb_salt = xr.open_mfdataset(\"/glade/campaign/cgd/cesm/CESM2-LE/timeseries/ocn/proc/tseries/month_1/SALT/b.e21.BHISTcmip6.f09_g17.LE2*.pop.h.SALT.196001-196912.nc\",\n",
    "                                 combine=\"nested\",\n",
    "                                 concat_dim=\"member_id\",\n",
    "                                ).mean('member_id')\n",
    "#ds_smbb_salt = ds_smbb_salt.sel(time=slice(\"1960\", \"1961\"))\n",
    "ds_smbb_salt = ds_smbb_salt.resample(time='1Y', closed='left').mean('time') # Yearly average\n",
    "salt = ds_smbb_salt['SALT'].isel(time=slice(0,10)).compute()\n",
    "salt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define sigma2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refz = 2000 # reference depth\n",
    "refdep = xr.full_like(salt,refz).rename('REFDEP')\n",
    "# Sigma2 on model TLAT, TLONG\n",
    "sigma2_T = pop_tools.eos(salt=salt,temp=temp,depth=refdep) - 1000\n",
    "sigma2_T = sigma2_T.assign_attrs({'long_name':'Sigma referenced to {}m'.format(refz),'units':'kg/m^3'})\n",
    "sigma2_T = sigma2_T.mean(dim=[\"time\"]) # Average over time\n",
    "# apply T-grid mask\n",
    "#mask=kindices<=ds['KMT'].values[None,:,:]\n",
    "#sigma2_T = sigma2_T.where(mask)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pop_tools.eos(salt=salt,temp=temp,depth=refdep) - 1000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "salt.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target sigma-2 vertical grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use predefined 86-layer sigma2 grid:\n",
    "sigma_mid,sigma_edge = popmoc.sigma2_grid_86L()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sigma_mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute MOC(Sigma2) using xhistogram "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fpop = '/glade/scratch/yeager/POP_MOC/g210.GIAF_JRA.v14.gx1v7.02.pop.h.0157-01.nc'\n",
    "ds = xr.open_dataset(fpop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute Isopycnal Layer Thickness"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(dask.distributed.__version__)\n",
    "print(pop_tools.__version__)\n",
    "print(xr.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sigma2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here, test histogram by counting cells in each density bin. Vertical sum should be same as KMT.\n",
    "iso_count = histogram(sigma2_T, bins=[sigma_edge.values],dim=['z_t'],density=False)\n",
    "iso_count = iso_count.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "kmtdiff = (iso_count.sum('sigma') - ds_smbb_temp['KMT'].mean(dim=[\"time\"]))\n",
    "print(\"Max difference from true KMT = {}\".format(abs(kmtdiff).max().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use histogram to compute layer thickness. Vertical sum should be same as HT.\n",
    "dzwgts = (ds_smbb_temp['dz']/100.).assign_attrs({'units':'m'})\n",
    "dzwgts = dzwgts.mean(dim=[\"time\"]) # Average over time\n",
    "iso_thick = histogram(sigma2_T, bins=[sigma_edge.values], weights=dzwgts,dim=['z_t'],density=False)\n",
    "iso_thick = iso_thick.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "iso_thick = iso_thick.rename('Isopycnal Layer Thickness').assign_attrs({'units':'m'})\n",
    "htdiff = iso_thick.sum('sigma') - (ds_smbb_temp['HT']/100.).assign_attrs({'units':'m'})\n",
    "htdiff = htdiff.mean(dim=[\"time\"]) # Average over time\n",
    "print(\"Max difference from true HT = {}m\".format(abs(htdiff).max().values))\n",
    "#In the original Notebook, the maximum difference is: HT = 1.2270752449694555e-05m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute Isopycnal Layer Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum of layer thickness yields depth of layer edges:\n",
    "iso_depth = iso_thick.cumsum('sigma').rename('Isopycnal Layer Depth')\n",
    "iso_depth['sigma'] = sigma_edge.isel(sigma=slice(1,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_depth.isel(sigma=84).plot(size=6,vmax=5500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isopycnal depth of bottom edge should be same as HT.\n",
    "htdiff =  iso_depth.isel(sigma=-1) - (ds_smbb_temp['HT']/100.).assign_attrs({'units':'m'})\n",
    "htdiff = htdiff.mean(dim=[\"time\"]) # Average over time\n",
    "print(\"Max difference from true HT = {}m\".format(abs(htdiff).max().values))\n",
    "#Max difference from true HT = 1.2270752449694555e-05m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute Isopycnal Layer Horizontal Volume Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid-oriented Volume FLuxes:\n",
    "uvel = uvel.where(uvel<1.e30).fillna(0.)\n",
    "vvel = vvel.where(vvel<1.e30).fillna(0.)\n",
    "uvel = (uvel*ds_smbb_uvel['DYU']*ds_smbb_uvel['dz']/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "vvel = (vvel*ds_smbb_vvel['DXU']*ds_smbb_vvel['dz']/1.e6).assign_attrs({'units':'m^3/s'})\n",
    "uvel = uvel.mean(dim=[\"time\"]) # Average over time\n",
    "vvel = vvel.mean(dim=[\"time\"]) # Average over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume fluxes in density-space. Vertical sum is density-space should reproduce vertical sum in depth-space.\n",
    "iso_uflux = histogram(sigma2_T, bins=[sigma_edge.values],weights=uvel,dim=['z_t'],density=False) # The 'numpy.histogram_bin_edges' function is not implemented by Dask array.\n",
    "iso_uflux = iso_uflux.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "iso_vflux = histogram(sigma2_T, bins=[sigma_edge.values],weights=vvel,dim=['z_t'],density=False)\n",
    "iso_vflux = iso_vflux.rename({'density_bin':'sigma'}).assign_coords({'sigma':sigma_mid})\n",
    "\n",
    "ufluxdiff = iso_uflux.sum('sigma') - uvel.sum('z_t')\n",
    "vfluxdiff = iso_vflux.sum('sigma') - vvel.sum('z_t')\n",
    "print(\"Max difference from true Uflux = {}\".format(abs(ufluxdiff).max().values))\n",
    "print(\"Max difference from true Vflux = {}\".format(abs(vfluxdiff).max().values))\n",
    "#Max difference from true Uflux = 1367813.3765927013\n",
    "#Max difference from true Vflux = 456888.7641561439"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to investigate these differences, which appear to be associated with overflows. The difference plot below shows zero almost everywhere except near Nordic Seas overflow points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufluxdiff.plot(size=7,vmin=-1.e5,vmax=1.e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compute Vertical Volume Flux using model divergence operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wflux = popmoc.pop_isowflux(iso_uflux,iso_vflux,'sigma',sigma_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Compute Zonal Sums of Vertical Volume Flux in latitude strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predefined 1-degree target latitude grid:\n",
    "lat_mid,lat_edge = popmoc.latitude_grid_1deg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define MOC region mask with legend:\n",
    "rmask = ds_smbb_temp.REGION_MASK\n",
    "rmask=rmask.mean(dim=[\"time\"])\n",
    "rmaskmoc = rmask.where(rmask>0)\n",
    "rmaskmoc = xr.where((rmask>0),1,rmaskmoc)\n",
    "rmaskmoc = xr.where((rmask>=6) & (rmask<=11),2,rmaskmoc)\n",
    "rmaskmoc.plot(levels=[0,1,2,3]);\n",
    "rmaskmoc.attrs['legend'] = {0:\"Global\",1:\"IndoPac+SO\",2:\"Atlantic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarea = ds_smbb_temp['TAREA']\n",
    "tarea=tarea.mean(dim=[\"time\"])\n",
    "tlat = ds_smbb_temp['TLAT']\n",
    "wflux_zonsum = popmoc.mesh_zonalavg(wflux,tarea,tlat,rmaskmoc,rmaskmoc.legend,lat_edge,sum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Compute cumulative meridional integral of zonally-summed wflux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A southward cumulative integral from 90N avoids issues associated with southern boundary of Atlantic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc = -wflux_zonsum.sel(lat=slice(None,None,-1)).cumsum('lat').sel(lat=slice(None,None,-1))\n",
    "moc = (moc/1.e6).assign_attrs({'units':'Sv'})   \n",
    "moc.name = 'MOC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=0).plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=1).plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=2).plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moc.isel(region=[1,2]).sum('region').plot(size=7,vmax=40,levels=21)\n",
    "plt.ylim([38,29])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2022b",
   "language": "python",
   "name": "npl-2022b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
