{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CESM2 - LARGE ENSEMBLE (LENS2)\n",
    "\n",
    "- This Notebooks aims to compute the heat balance in the South Atlantic, defined by the difference of the meridional heat transport from the northern and southern boundaries and the total surface heat flux (area integral) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import dask\n",
    "import cf_xarray\n",
    "import intake\n",
    "import cftime\n",
    "import nc_time_axis\n",
    "import intake_esm\n",
    "import matplotlib.pyplot as plt\n",
    "import pop_tools\n",
    "from dask.distributed import Client, wait\n",
    "from ncar_jobqueue import NCARCluster\n",
    "import warnings, getpass, os\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import cartopy.crs as ccrs\n",
    "import cmocean\n",
    "import dask\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_per_worker = 60 # memory per worker in GB \n",
    "num_workers = 40 # number of workers\n",
    "cluster = NCARCluster(cores=1, processes=1, memory=f'{mem_per_worker} GB',resource_spec=f'select=1:ncpus=1:mem={mem_per_worker}GB', walltime='2:00:00')\n",
    "cluster.scale(num_workers)\n",
    "client = Client(cluster)\n",
    "print(client)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = intake.open_esm_datastore(\n",
    "    '/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cesm2-le.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_subset = catalog.search(component='ocn',variable=['TEND_TEMP','SHF','N_HEAT'],frequency='month_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog entries for subset into a dictionary of xarray datasets\n",
    "dset_dict_raw  = cat_subset.to_dataset_dict(zarr_kwargs={'consolidated': True}, storage_options={'anon': True})\n",
    "print(f'\\nDataset dictionary keys:\\n {dset_dict_raw.keys()}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load catalog entries for subset into a dictionary of xarray datasets\n",
    "dset_dict_raw  = cat_subset.to_dataset_dict(zarr_kwargs={'consolidated': True}, cdf_kwargs={'chunks': {'time': 12}}, storage_options={'anon': True})\n",
    "print(f'\\nDataset dictionary keys:\\n {dset_dict_raw.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=('cmip6','smbb')               # Forcings\n",
    "fb=(['TEND_TEMP','SHF','N_HEAT']) # Variable\n",
    "\n",
    "ds_dict = dict()\n",
    "for var in fb:\n",
    "    # 1- combine historical and ssp370 (concatenate in time)\n",
    "    ds_dict_tmp = dict()\n",
    "    for scenario in ff:\n",
    "        ds_dict_tmp[scenario] = xr.combine_nested([dset_dict_raw[f'ocn.historical.pop.h.{scenario}.{var}'], dset_dict_raw[f'ocn.ssp370.pop.h.{scenario}.{var}']],concat_dim=['time'])\n",
    "        \n",
    "        # 2- combine cmip6 and smbb (concatenate in member_id)\n",
    "    ds_dict[var] = xr.combine_nested([ds_dict_tmp['cmip6'], ds_dict_tmp['smbb']], concat_dim=['member_id'])\n",
    "    del ds_dict_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz=ds_dict['TEND_TEMP']['dz'].isel(time=0,member_id=0)*0.01 # 0.01 to convert cm into m \n",
    "# Test\n",
    "dz.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import POP grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_grid = pop_tools.get_grid('POP_gx1v7')\n",
    "ds_dict['TLONG'] = pop_grid.TLONG; ds_dict['TLAT'] = pop_grid.TLAT\n",
    "ds_dict['ULONG'] = pop_grid.ULONG; ds_dict['ULAT'] = pop_grid.ULAT\n",
    "del pop_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the difference in heat transport to latitudes closer to the equator and 34S\n",
    "- We chose 34 instead of 34.5S because at 34S we are sure that there is no water leakage South Africa "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['N_HEAT']['N_HEAT'].coords['lat_aux_grid'][190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#ilan = 0 # northernmost latitude\n",
    "ilas = -34 # southernmost latitude\n",
    "Vt_n=ds_dict['N_HEAT']['N_HEAT'].isel(transport_reg=1).sum(dim='transport_comp').isel(lat_aux_grid=190).load()\n",
    "Vt_s=ds_dict['N_HEAT']['N_HEAT'].isel(transport_reg=1).sum(dim='transport_comp').sel(lat_aux_grid=ilas,method='nearest').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt_n.coords['time'][3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(x):\n",
    "    return slope * x + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meridional Heat Transport Difference\n",
    "Vt_s_trends=Vt_s.resample(time='1Y', closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).mean('member_id')\n",
    "\n",
    "Vt_n_trends=Vt_n.resample(time='1Y', closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).mean('member_id')\n",
    "\n",
    "Vt_sn_trends=(Vt_n-Vt_s).resample(time='1Y', closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).mean('member_id')\n",
    "\n",
    "x=np.squeeze(range(0,len(Vt_s_trends)))\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, Vt_s_trends)\n",
    "mymodel_Vt_s_trends = list(map(myfunc, x))\n",
    "mymodel_Vt_s_trends=mymodel_Vt_s_trends\n",
    "m_Vt_s_trends=slope*10 # per decade\n",
    "p_Vt_s_trends=p\n",
    "r_Vt_s_trends=r*r\n",
    "\n",
    "x=np.squeeze(range(0,len(Vt_n_trends)))\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, Vt_n_trends)\n",
    "mymodel_Vt_n_trends = list(map(myfunc, x))\n",
    "mymodel_Vt_n_trends=mymodel_Vt_n_trends\n",
    "m_Vt_n_trends=slope*10 # per decade\n",
    "p_Vt_n_trends=p\n",
    "r_Vt_n_trends=r*r\n",
    "\n",
    "x=np.squeeze(range(0,len(Vt_sn_trends)))\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, Vt_sn_trends)\n",
    "mymodel_Vt_sn_trends = list(map(myfunc, x))\n",
    "mymodel_Vt_sn_trends=mymodel_Vt_sn_trends\n",
    "m_Vt_sn_trends=slope*10 # per decade\n",
    "p_Vt_sn_trends=p\n",
    "r_Vt_sn_trends=r*r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "Vt_s.mean('member_id').sel(time=slice('1850-01-01','2100-12-31')).resample(time='1Y', closed='left').mean('time').plot(\n",
    "    x=\"time\",color='purple',linewidth=1,label=r'$\\rm{MHT}: 34^oS$')\n",
    "plt.plot(Vt_s.resample(time='1Y', closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).coords['time'],mymodel_Vt_s_trends,color='purple',linestyle='dashed')\n",
    "plt.annotate(f'{m_Vt_s_trends*1000:.2f} TW per decade', xy=(0.4, 0.1), color='purple',fontsize=20,xycoords=ax.transAxes)\n",
    "\n",
    "\n",
    "Vt_n.mean('member_id').sel(time=slice('1850-01-01','2100-12-31')).resample(time='1Y', closed='left').mean('time').plot(\n",
    "    x=\"time\",color='orange',linewidth=1,label=r'$\\rm{MHT}: 0^o$')\n",
    "plt.plot(Vt_n.resample(time='1Y', closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).coords['time'],mymodel_Vt_n_trends,color='orange',linestyle='dashed')\n",
    "plt.annotate(f'{m_Vt_n_trends*1000:.2f} TW per decade', xy=(0.4, 0.6), color='orange',fontsize=20,xycoords=ax.transAxes)\n",
    "\n",
    "\n",
    "(Vt_n-Vt_s).mean('member_id').sel(time=slice('1850-01-01','2100-12-31')).resample(time='1Y', closed='left').mean('time').plot(\n",
    "    x=\"time\",color='red',linewidth=1,label=r'$\\rm{MHTD}: 0^o-34^oS$')\n",
    "plt.plot((Vt_n-Vt_s).resample(time='1Y', closed='left').mean('time').sel(time=slice('2015-01-01','2100-12-31')).coords['time'],mymodel_Vt_sn_trends,color='red',linestyle='dashed')\n",
    "plt.annotate(f'{m_Vt_sn_trends*1000:.2f} TW per decade', xy=(0.6, 0.38), color='red',fontsize=20,xycoords=ax.transAxes)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize=20)\n",
    "plt.ylabel(r'Heat Flux [PW]',fontsize=20)\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.7)\n",
    "plt.title(None)\n",
    "plt.ylim(0.15,0.85)\n",
    "plt.xlim(Vt_n.coords['time'][1319].values,Vt_n.coords['time'][3000].values)\n",
    "plt.vlines(Vt_n.sel(time=slice('2015-01-01','2100-12-31')).coords['time'][0].values,0,0.9,linestyle='dashed',color=\"black\")\n",
    "plt.xlabel('Time [Years]',fontsize=20)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "plt.savefig('MHT.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ilan = 0 # northernmost latitude\n",
    "ilas = -34 # southernmost latitude\n",
    "ds_N_HEAT_diff=(ds_dict['N_HEAT']['N_HEAT'].isel(transport_reg=1,lat_aux_grid=190)-ds_dict['N_HEAT']['N_HEAT'].isel(transport_reg=1).sel(lat_aux_grid=ilas,method='nearest')).sum(dim='transport_comp').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut and center the variable in the South Atlantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cutting out and centering the variables in the South Atlantic\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": True})\n",
    "ilon1, flon1, ilon2, flon2 = 307, 320, 0, 54 # longitude (initial (i), final (f)) \n",
    "\n",
    "fb=(['TEND_TEMP','SHF'])\n",
    "\n",
    "for var in fb:\n",
    "    ds_dict[f'{var}']=xr.combine_nested([[\n",
    "        ds_dict[f'{var}'].where((ds_dict[f'{var}'].TLAT >= ilas) & (ds_dict[f'{var}'].TLAT <= ilan), drop=True).isel(\n",
    "            nlon = slice(ilon1,flon1)),\n",
    "        ds_dict[f'{var}'].where((ds_dict[f'{var}'].TLAT >= ilas) & (ds_dict[f'{var}'].TLAT <= ilan), drop=True).isel(\n",
    "            nlon = slice(ilon2,flon2))]],\n",
    "        concat_dim=['nlat','nlon'])   \n",
    "    ds_dict[f'{var}'].coords['nlon'] = (ds_dict[f'{var}'].coords['nlon'] + 180) % 360 - 180 \n",
    "    ds_dict[f'{var}'] = ds_dict[f'{var}'].sortby(ds_dict[f'{var}'].nlon)\n",
    "del ilan, ilas, ilon1, flon1, ilon2, flon2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict['TEND_TEMP']['TEND_TEMP'].isel(member_id=0,time=0,z_t=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask the continent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb=(['TEND_TEMP','SHF'])\n",
    "for var in fb:\n",
    "    mask_array = dict()\n",
    "    mask_ocean = 2 * np.ones((len(ds_dict[f'{var}'][f'{var}'].coords['nlat']), # ocean\n",
    "                          len(ds_dict[f'{var}'][f'{var}'].coords['nlon']))\n",
    "                        ) * np.isfinite(ds_dict[f'{var}'][f'{var}'].isel(time=0))  \n",
    "    mask_land  = 1 * np.ones((len(ds_dict[f'{var}'][f'{var}'].coords['nlat']), # continent\n",
    "                          len(ds_dict[f'{var}'][f'{var}'].coords['nlon']))\n",
    "                        ) * np.isnan(ds_dict[f'{var}'][f'{var}'].isel(time=0))  \n",
    "    mask_array[f'{var}'] = mask_ocean + mask_land\n",
    "    ds_dict[f'{var}']['TAREA']=ds_dict[f'{var}']['TAREA'].where(mask_array[f'{var}'] != 1.).isel(time=0)*1e-4 # 1e-4 to convert cm2 into m2\n",
    "    del mask_array"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['SHF']['TAREA'].isel(member_id=0).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['SHF']['TAREA'].isel(member_id=0).plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['SHF']['SHF'].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['SHF']['SHF'].isel(member_id=0,time=0).plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['TEND_TEMP']['TEND_TEMP'].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['TEND_TEMP']['TEND_TEMP'].isel(member_id=0,time=0,z_t=0).plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['TEND_TEMP']['TEND_TEMP'].isel(member_id=0,time=0,z_t=-10).plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['TEND_TEMP']['TAREA'].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['TEND_TEMP']['TAREA'].isel(z_t=0,member_id=0).plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_dict['TEND_TEMP']['TAREA'].isel(z_t=-10,member_id=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate the SHF in the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict['SHF']['TAREA']=ds_dict['SHF']['TAREA'].chunk(chunks=(50,1,67))\n",
    "ds_dict['SHF']['SHF']=ds_dict['SHF']['SHF'].chunk(chunks=(50,1980,1,67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_SHF=ds_dict['SHF']['TAREA']*ds_dict['SHF']['SHF']*(1e-15) # PW (1e-15 to convert the units from W to PW) \n",
    "ds_SHF=ds_SHF.sum(dim=['nlat','nlon'],skipna=True).load() # PW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "ds_N_HEAT_diff.mean('member_id').resample(time='1Y', closed='left').mean('time').sel(time=slice('1851-01-01','2100-12-31')).plot(label='MHTD')\n",
    "ds_SHF.mean('member_id').resample(time='1Y', closed='left').mean('time').sel(time=slice('1851-01-01','2100-12-31')).plot(label='SHF')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Time [Years]')\n",
    "plt.ylabel('PW')\n",
    "#plt.savefig('Heat_balance.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the heat balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_SHF_N_HEAT_diff=ds_SHF-ds_N_HEAT_diff # PW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "ds_SHF_N_HEAT_diff.mean('member_id').resample(time='1Y', closed='left').mean('time').sel(time=slice('1851-01-01','2100-12-31')).plot(label='HS',color='red')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(None)\n",
    "plt.xlabel('Time [Years]')\n",
    "plt.ylabel('PW')\n",
    "#plt.savefig('Heat_storage.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Here it was necessary to do the difference and not the sum of the terms to get the heat balance. This is because the SHF convection is positive to the ocean. The balance is given by every heat flux entering from the surface (positive direction of the z-axis) is equal to every flux leaving from the meridional heat transport (positive direction of the y-axis). The meirdional heat transport has a positive y-axis direction, but the SHF has not a negative z-axis direction. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the heat storage (HS) to compare with the heat storage due to the difference between the heat fluxes\n",
    "- the vertical integral of the temperature tendency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equation: $$\\rm{HS = \\uprho_\\uptheta~C_p~\\int_{z_2}^{z_1}\\uptheta_{(z)}'~dz},$$\n",
    "##### where:\n",
    "##### * HS is heat storage ($\\rm{J~m^{-2}}$),\n",
    "##### * $\\uprho_\\uptheta$ is the density of sea water,\n",
    "##### * $\\rm{C_p}$ is the specific heat of sea water,\n",
    "##### * $\\rm{z}$ is the depth limit on the calculation in meters,\n",
    "##### * and $\\uptheta$' is the potential temperature monthly anomaly (successor month minus previous month) at each depth in degress Kelvin or Celsius or, the temperature tendency. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "ds_sa_TEMP_anom = ds_sa_TEMP_anom.persist()\n",
    "wait(ds_sa_TEMP_anom)\n",
    "ds_sa_TEMP_anom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "warnings.simplefilter(\"ignore\")\n",
    "var_array = list() # Build a list\n",
    "for member_id in range(len(ds_dict['TEND_TEMP']['TEND_TEMP'].coords['member_id'])): # per member\n",
    "    ds_HS_TEMP=ds_dict['TEND_TEMP']['TEND_TEMP'].isel(member_id=member_id)*dz # 1- Multiply by dz. Unit: oC.s-1.m \n",
    "    ds_HS_TEMP=ds_HS_TEMP*ds_dict['TEND_TEMP']['TAREA'].isel(\n",
    "        member_id=member_id) # 2- Multiply by the area. Unit: oC.s-1.m3\n",
    "    ds_HS_TEMP=ds_HS_TEMP.sum(dim=['z_t','nlon','nlat']) # 3- Integral in dz,dy,dx. Unit: oC.s-1.m3\n",
    "    ds_HS_TEMP=ds_HS_TEMP*1026 # 4- Multiply by the density of the sea water. Unit: oC.s-1.kg\n",
    "    ds_HS_TEMP=ds_HS_TEMP*3996 # 5- Multiply by the heat capacity of the sea water. Unit: W\n",
    "    ds_HS_TEMP=ds_HS_TEMP*1e-15 # 6- Get the variable in PW \n",
    "    var_small=ds_HS_TEMP.load() # 7- Annual mean and load\n",
    "    var_array.append(var_small) # 8- Add items to the end of a given list\n",
    "    del ds_HS_TEMP \n",
    "    print(f'Done with member: {member_id}') # 9- Go to the next member\n",
    "ds_HS_TEMP_merged = xr.concat(var_array, dim='member_id', compat='override', join='override', coords='minimal') # 10- Concat the members    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test\n",
    "ds_HS_TEMP_merged.sel(time=slice('1852-01-01','2100-12-31')).mean('member_id').resample(time='1Y', closed='left').mean('time').plot()\n",
    "ds_SHF_N_HEAT_diff.mean('member_id').resample(time='1Y', closed='left').mean('time').sel(time=slice('1852-01-01','2100-12-31')).plot(label='HS',color='red')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_out_var = xr.merge([ds_HS_TEMP_merged.rename('HS_TEND_TEMP'), # Heat Storage from temperature tendency\n",
    "                       ds_SHF_N_HEAT_diff.rename('HS'), # Heat Storage from SHF-N_HEAT\n",
    "                       ds_N_HEAT_diff.rename('MHTD'), # Meridional Heat Transport Difference\n",
    "                       ds_SHF.rename('SHF')]) # Total Surface Heat Flux\n",
    "ds_out_var.attrs['description'] = 'Heat balance components for the South Atlantic'\n",
    "ds_out_var.attrs['units'] = 'PW'\n",
    "ds_out_var.attrs['author'] = 'Mauricio Rocha'\n",
    "ds_out_var.attrs['email'] = 'mauricio.rocha@usp.br'\n",
    "# create a directory on scratch to save the output\n",
    "path = '/glade/scratch/mauricio/Data/LENS2/HEAT_BALANCE/'.format(getpass.getuser())\n",
    "os.system('mkdir -p '+path)\n",
    "ds_out_var.to_netcdf(path+'heat_balance_components.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the heat stored per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "warnings.simplefilter(\"ignore\")\n",
    "#layers=('0','1e+5','2e+5')\n",
    "layers=('0','1e+5','6e+5')\n",
    "for layer in range(0,len(layers)-1):\n",
    "    print(f'Done with layer: {layer}')\n",
    "    var_array = list() # Build a list\n",
    "    for member_id in range(len(ds_dict['TEND_TEMP']['TEND_TEMP'].coords['member_id'])): # per member\n",
    "        st=f'ds_HS_TEMP=ds_dict[\\'TEND_TEMP\\'][\\'TEND_TEMP\\'].isel(member_id=member_id).sel(z_t=slice({layers[layer]},{layers[layer+1]}))*dz.sel(z_t=slice({layers[layer]},{layers[layer+1]}))' # 1- Multiply by dz. Unit: oC.s-1.m\n",
    "        exec(st); del st\n",
    "        st=f'ds_HS_TEMP=ds_HS_TEMP*ds_dict[\\'TEND_TEMP\\'][\\'TAREA\\'].isel(member_id=member_id).sel(z_t=slice({layers[layer]},{layers[layer+1]}))' # 2- Multiply by the area. Unit: oC.s-1.m3\n",
    "        exec(st); del st\n",
    "        ds_HS_TEMP=ds_HS_TEMP.sum(dim=['z_t','nlon','nlat']) # 3- Integral in dz,dy,dx. Unit: oC.s-1.m3\n",
    "        ds_HS_TEMP=ds_HS_TEMP*1026 # 4- Multiply by the density of the sea water. Unit: oC.s-1.kg\n",
    "        ds_HS_TEMP=ds_HS_TEMP*3996 # 5- Multiply by the heat capacity of the sea water. Unit: W\n",
    "        ds_HS_TEMP=ds_HS_TEMP*1e-15 # 6- Get the variable in PW \n",
    "        var_small=ds_HS_TEMP.load() # 7- Annual mean and load\n",
    "        var_array.append(var_small) # 8- Add items to the end of a given list\n",
    "        del ds_HS_TEMP \n",
    "        print(f'Done with member: {member_id}') # 9- Go to the next member\n",
    "    st=f'ds_HS_TEMP_merged_{layer} = xr.concat(var_array, dim=\\'member_id\\', compat=\\'override\\', join=\\'override\\', coords=\\'minimal\\')' # 10- Concat the members   \n",
    "    exec(st); del st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_HS_TEMP_merged_0.sel(time=slice('1852-01-01','2100-12-31')).mean('member_id').resample(time='1Y', closed='left').mean('time').plot(label='0-1000')\n",
    "ds_HS_TEMP_merged_1.sel(time=slice('1852-01-01','2100-12-31')).mean('member_id').resample(time='1Y', closed='left').mean('time').plot(label='1000-6000')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out_var = xr.merge([ds_HS_TEMP_merged_0.rename('HS_0'), # Heat Storage (first layer)\n",
    "                       ds_HS_TEMP_merged_1.rename('HS_1'), # Heat Storage (second layer)\n",
    "                      ]) # Total Surface Heat Flux\n",
    "ds_out_var.attrs['description'] = 'Heat balance components per layers for the South Atlantic: HS_0 (0-1000m), HS_1 (1000-6000m)'\n",
    "ds_out_var.attrs['units'] = 'PW'\n",
    "ds_out_var.attrs['author'] = 'Mauricio Rocha'\n",
    "ds_out_var.attrs['email'] = 'mauricio.rocha@usp.br'\n",
    "# create a directory on scratch to save the output\n",
    "path = '/glade/scratch/mauricio/Data/LENS2/HEAT_BALANCE/'.format(getpass.getuser())\n",
    "os.system('mkdir -p '+path)\n",
    "ds_out_var.to_netcdf(path+'heat_storage_per_layer_0_6000m.nc')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### 5- Compute the difference in days in each month"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "dt = np.empty((len(ds_dict['TEMP']['time_bound'].coords['time']))) * np.nan\n",
    "for it in range(len(ds_dict['TEMP']['time_bound'].coords['time'])):\n",
    "    dt[it]=np.abs(ds_dict['TEMP']['time_bound'].isel(\n",
    "        member_id=0,nlon=0,nlat=0,time=it,d2=0).values-ds_dict['TEMP']['time_bound'].isel(\n",
    "        member_id=0,nlon=0,nlat=0,time=it,d2=1).values).days"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### 6- Calculate the difference between one month and the following month of heat storage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "ds_HS_TEMP = ds_HS_TEMP.diff('time') # J"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds_HS_TEMP_PW=ds_HS_TEMP*(1e-15)/(60*60*24*dt[0:-1]) # PW (1e-15 to get the results in PW) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2022b",
   "language": "python",
   "name": "npl-2022b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
